"""
Evaluate a saved model on a dataset.
"""
from __future__ import annotations
import argparse, os, joblib
from sklearn.metrics import classification_report, roc_auc_score
from data import load_dataset

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data", required=True)
    ap.add_argument("--text_col", default="text")
    ap.add_argument("--label_col", default="label")
    ap.add_argument("--model_dir", default="models")
    args = ap.parse_args()

    df = load_dataset(args.data, args.text_col, args.label_col)
    model_path = os.path.join(args.model_dir, "model.joblib")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model not found at {model_path}. Run train.py first.")
    pipe = joblib.load(model_path)

    probs = pipe.predict_proba(df["text"])[:,1]
    preds = (probs >= 0.5).astype(int)

    print(classification_report(df["label"], preds, target_names=["real","fake"]))
    try:
        auc = roc_auc_score(df["label"], probs)
        print(f"ROC-AUC: {auc:.4f}")
    except Exception:
        pass

if __name__ == "__main__":
    main()
